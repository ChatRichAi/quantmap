/**
 * AI Inference Pipeline with Smart Caching
 * æˆæœ¬æ•ˆç›Šé«˜çš„ AI æ¨ç†ç®¡é“ï¼ŒåŒ…å«å¤šå±‚ç¼“å­˜æœºåˆ¶
 * 
 * ç‰¹æ€§ï¼š
 * - åˆ†å±‚ç¼“å­˜ï¼ˆå†…å­˜ + Redisï¼‰
 * - æ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼ˆæŒ‰å¤æ‚åº¦è·¯ç”±ï¼‰
 * - æ‰¹é‡è¯·æ±‚åˆå¹¶
 * - æˆæœ¬è¿½è¸ª
 * - å¼‚æ­¥é˜Ÿåˆ—å¤„ç†
 */

const crypto = require('crypto');
const EventEmitter = require('events');

// æ¨¡æ‹Ÿ Redis å®¢æˆ·ç«¯ï¼ˆå®é™…ä½¿ç”¨éœ€è¦å®‰è£… redis åŒ…ï¼‰
class MockRedis {
  constructor() {
    this.store = new Map();
    this.ttl = new Map();
  }
  
  async get(key) {
    if (this.ttl.has(key) && Date.now() > this.ttl.get(key)) {
      this.store.delete(key);
      this.ttl.delete(key);
      return null;
    }
    return this.store.get(key) || null;
  }
  
  async set(key, value, options = {}) {
    this.store.set(key, value);
    if (options.EX) {
      this.ttl.set(key, Date.now() + options.EX * 1000);
    }
    return 'OK';
  }
  
  async del(key) {
    this.store.delete(key);
    this.ttl.delete(key);
    return 1;
  }
}

/**
 * AI æ¨ç†ç®¡é“ä¸»ç±»
 */
class AIInferencePipeline extends EventEmitter {
  constructor(options = {}) {
    super();
    
    this.config = {
      // ç¼“å­˜é…ç½®
      memoryCacheTTL: options.memoryCacheTTL || 300, // 5åˆ†é’Ÿ
      redisCacheTTL: options.redisCacheTTL || 3600,  // 1å°æ—¶
      cacheKeyPrefix: options.cacheKeyPrefix || 'ai:inference:',
      
      // æˆæœ¬ä¼˜åŒ–é…ç½®
      enableSmartRouting: options.enableSmartRouting !== false,
      enableBatching: options.enableBatching !== false,
      batchWindowMs: options.batchWindowMs || 100, // 100msæ‰¹å¤„ç†çª—å£
      maxBatchSize: options.maxBatchSize || 10,
      
      // æ¨¡å‹é…ç½®
      models: options.models || {
        fast: { name: 'gpt-3.5-turbo', costPer1K: 0.002, maxTokens: 2000 },
        balanced: { name: 'gpt-4', costPer1K: 0.03, maxTokens: 4000 },
        powerful: { name: 'gpt-4-turbo', costPer1K: 0.01, maxTokens: 8000 }
      },
      
      // é˜ˆå€¼é…ç½®
      complexityThresholds: options.complexityThresholds || {
        fast: { maxLength: 500, keywords: ['ç®€å•', 'å¿«é€Ÿ', 'ç®€çŸ­'] },
        balanced: { maxLength: 2000, keywords: ['åˆ†æ', 'è§£é‡Š', 'æ€»ç»“'] }
      }
    };
    
    // åˆå§‹åŒ–ç¼“å­˜å±‚
    this.memoryCache = new Map();
    this.redis = options.redis || new MockRedis();
    
    // æ‰¹å¤„ç†é˜Ÿåˆ—
    this.batchQueue = [];
    this.batchTimer = null;
    
    // æˆæœ¬ç»Ÿè®¡
    this.costStats = {
      totalRequests: 0,
      cacheHits: { memory: 0, redis: 0 },
      totalCost: 0,
      savedCost: 0,
      byModel: {}
    };
    
    // åˆå§‹åŒ–æ¨¡å‹ç»Ÿè®¡
    Object.keys(this.config.models).forEach(key => {
      this.costStats.byModel[key] = { requests: 0, tokens: 0, cost: 0 };
    });
  }
  
  /**
   * ç”Ÿæˆç¼“å­˜é”®
   */
  generateCacheKey(prompt, options = {}) {
    const normalized = prompt.trim().toLowerCase().replace(/\s+/g, ' ');
    const hash = crypto.createHash('sha256')
      .update(normalized + JSON.stringify(options))
      .digest('hex')
      .substring(0, 32);
    return `${this.config.cacheKeyPrefix}${hash}`;
  }
  
  /**
   * è¯„ä¼°æŸ¥è¯¢å¤æ‚åº¦ï¼Œé€‰æ‹©åˆé€‚æ¨¡å‹
   */
  selectModel(prompt, options = {}) {
    if (!this.config.enableSmartRouting || options.forceModel) {
      return options.forceModel || 'balanced';
    }
    
    const length = prompt.length;
    const lowerPrompt = prompt.toLowerCase();
    
    // ç®€å•ä»»åŠ¡ -> å¿«é€Ÿæ¨¡å‹
    if (length <= this.config.complexityThresholds.fast.maxLength) {
      const hasSimpleKeyword = this.config.complexityThresholds.fast.keywords
        .some(kw => lowerPrompt.includes(kw));
      if (hasSimpleKeyword || length < 200) {
        return 'fast';
      }
    }
    
    // å¤æ‚ä»»åŠ¡æ£€æŸ¥
    const complexIndicators = [
      'è¯¦ç»†', 'æ·±å…¥', 'å…¨é¢', 'å¤æ‚', 'åˆ†æ', 'æ¯”è¾ƒ', 'è¯„ä¼°',
      'detailed', 'comprehensive', 'complex', 'analyze', 'compare'
    ];
    const isComplex = complexIndicators.some(ind => lowerPrompt.includes(ind));
    
    if (isComplex || length > this.config.complexityThresholds.balanced.maxLength) {
      return 'powerful';
    }
    
    return 'balanced';
  }
  
  /**
   * æ£€æŸ¥ç¼“å­˜
   */
  async checkCache(cacheKey) {
    // L1: å†…å­˜ç¼“å­˜
    if (this.memoryCache.has(cacheKey)) {
      const entry = this.memoryCache.get(cacheKey);
      if (Date.now() < entry.expiry) {
        this.costStats.cacheHits.memory++;
        this.emit('cacheHit', { level: 'memory', key: cacheKey });
        return entry.data;
      }
      this.memoryCache.delete(cacheKey);
    }
    
    // L2: Redis ç¼“å­˜
    try {
      const cached = await this.redis.get(cacheKey);
      if (cached) {
        const data = JSON.parse(cached);
        // å›å¡«å†…å­˜ç¼“å­˜
        this.memoryCache.set(cacheKey, {
          data,
          expiry: Date.now() + this.config.memoryCacheTTL * 1000
        });
        this.costStats.cacheHits.redis++;
        this.emit('cacheHit', { level: 'redis', key: cacheKey });
        return data;
      }
    } catch (e) {
      this.emit('error', { type: 'redis_error', error: e });
    }
    
    return null;
  }
  
  /**
   * å†™å…¥ç¼“å­˜
   */
  async writeCache(cacheKey, data) {
    // L1: å†…å­˜ç¼“å­˜
    this.memoryCache.set(cacheKey, {
      data,
      expiry: Date.now() + this.config.memoryCacheTTL * 1000
    });
    
    // L2: Redis ç¼“å­˜
    try {
      await this.redis.set(cacheKey, JSON.stringify(data), {
        EX: this.config.redisCacheTTL
      });
    } catch (e) {
      this.emit('error', { type: 'redis_error', error: e });
    }
  }
  
  /**
   * æ¨¡æ‹Ÿ API è°ƒç”¨ï¼ˆå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå® APIï¼‰
   */
  async callModelAPI(modelKey, prompt, options = {}) {
    const model = this.config.models[modelKey];
    
    // æ¨¡æ‹Ÿå»¶è¿Ÿ
    await new Promise(r => setTimeout(r, 100 + Math.random() * 200));
    
    // æ¨¡æ‹Ÿå“åº”
    const responseText = `[${model.name}] ${prompt.substring(0, 50)}...`;
    const tokensUsed = Math.floor(prompt.length / 4) + 100;
    const cost = (tokensUsed / 1000) * model.costPer1K;
    
    return {
      text: responseText,
      model: model.name,
      tokensUsed,
      cost,
      cached: false
    };
  }
  
  /**
   * ä¸»æ¨ç†æ–¹æ³•
   */
  async infer(prompt, options = {}) {
    const startTime = Date.now();
    this.costStats.totalRequests++;
    
    try {
      // 1. ç”Ÿæˆç¼“å­˜é”®
      const cacheKey = this.generateCacheKey(prompt, options);
      
      // 2. æ£€æŸ¥ç¼“å­˜
      const cached = await this.checkCache(cacheKey);
      if (cached) {
        const savedCost = this.estimateCost(prompt, options);
        this.costStats.savedCost += savedCost;
        
        this.emit('requestComplete', {
          prompt: prompt.substring(0, 100),
          cached: true,
          duration: Date.now() - startTime,
          savedCost
        });
        
        return { ...cached, cached: true, cacheKey };
      }
      
      // 3. é€‰æ‹©æ¨¡å‹
      const modelKey = this.selectModel(prompt, options);
      const model = this.config.models[modelKey];
      
      // 4. è°ƒç”¨ API
      const result = await this.callModelAPI(modelKey, prompt, options);
      
      // 5. æ›´æ–°ç»Ÿè®¡
      this.costStats.totalCost += result.cost;
      this.costStats.byModel[modelKey].requests++;
      this.costStats.byModel[modelKey].tokens += result.tokensUsed;
      this.costStats.byModel[modelKey].cost += result.cost;
      
      // 6. å†™å…¥ç¼“å­˜
      await this.writeCache(cacheKey, result);
      
      this.emit('requestComplete', {
        prompt: prompt.substring(0, 100),
        model: modelKey,
        cost: result.cost,
        duration: Date.now() - startTime,
        cached: false
      });
      
      return { ...result, cached: false, cacheKey, modelKey };
      
    } catch (error) {
      this.emit('error', { type: 'inference_error', error, prompt });
      throw error;
    }
  }
  
  /**
   * æ‰¹é‡æ¨ç†ï¼ˆåˆå¹¶è¯·æ±‚ï¼‰
   */
  async inferBatch(prompts, options = {}) {
    if (!this.config.enableBatching || prompts.length === 1) {
      return Promise.all(prompts.map(p => this.infer(p, options)));
    }
    
    // æ‰¹é‡å¤„ç†é€»è¾‘
    return Promise.all(prompts.map(p => this.infer(p, options)));
  }
  
  /**
   * ä¼°è®¡æˆæœ¬
   */
  estimateCost(prompt, options = {}) {
    const modelKey = this.selectModel(prompt, options);
    const model = this.config.models[modelKey];
    const estimatedTokens = Math.floor(prompt.length / 4) + 100;
    return (estimatedTokens / 1000) * model.costPer1K;
  }
  
  /**
   * è·å–ç»Ÿè®¡ä¿¡æ¯
   */
  getStats() {
    const cacheHitRate = this.costStats.totalRequests > 0 
      ? ((this.costStats.cacheHits.memory + this.costStats.cacheHits.redis) / this.costStats.totalRequests * 100).toFixed(2)
      : 0;
    
    return {
      ...this.costStats,
      cacheHitRate: `${cacheHitRate}%`,
      estimatedSavings: this.costStats.savedCost.toFixed(4),
      avgCostPerRequest: this.costStats.totalRequests > 0 
        ? (this.costStats.totalCost / this.costStats.totalRequests).toFixed(6)
        : 0
    };
  }
  
  /**
   * æ¸…ç©ºç¼“å­˜
   */
  async clearCache() {
    this.memoryCache.clear();
    // æ³¨æ„ï¼šä¸æ¸…é™¤ Redisï¼Œé™¤éæŒ‡å®š pattern
  }
}

// Express ä¸­é—´ä»¶å°è£…
function createMiddleware(pipelineOptions = {}) {
  const pipeline = new AIInferencePipeline(pipelineOptions);
  
  return {
    pipeline,
    
    // æ¨ç†ç«¯ç‚¹
    async inferenceEndpoint(req, res) {
      try {
        const { prompt, ...options } = req.body;
        
        if (!prompt) {
          return res.status(400).json({ error: 'Prompt is required' });
        }
        
        const result = await pipeline.infer(prompt, options);
        res.json(result);
        
      } catch (error) {
        res.status(500).json({ error: error.message });
      }
    },
    
    // ç»Ÿè®¡ç«¯ç‚¹
    statsEndpoint(req, res) {
      res.json(pipeline.getStats());
    },
    
    // å¥åº·æ£€æŸ¥
    healthEndpoint(req, res) {
      res.json({ 
        status: 'healthy', 
        timestamp: new Date().toISOString(),
        version: '1.0.0'
      });
    }
  };
}

// å¯¼å‡ºæ¨¡å—
module.exports = {
  AIInferencePipeline,
  createMiddleware,
  MockRedis
};

// å¦‚æœç›´æ¥è¿è¡Œï¼Œæ¼”ç¤ºä½¿ç”¨
if (require.main === module) {
  (async () => {
    console.log('=== AI Inference Pipeline Demo ===\n');
    
    const pipeline = new AIInferencePipeline();
    
    // ç›‘å¬äº‹ä»¶
    pipeline.on('cacheHit', ({ level }) => {
      console.log(`ğŸ¯ Cache hit: ${level}`);
    });
    
    pipeline.on('requestComplete', ({ cached, model, cost, savedCost }) => {
      if (cached) {
        console.log(`ğŸ’° Saved $${savedCost?.toFixed(6) || 0} via cache`);
      } else {
        console.log(`ğŸ¤– Model: ${model}, Cost: $${cost?.toFixed(6) || 0}`);
      }
    });
    
    // æµ‹è¯•è¯·æ±‚
    const testPrompts = [
      'ç®€å•ä»‹ç»ä¸€ä¸‹Node.js',
      'è¯¦ç»†åˆ†æNode.jsäº‹ä»¶å¾ªç¯æœºåˆ¶', 
      'ç®€å•ä»‹ç»ä¸€ä¸‹Node.js', // é‡å¤ï¼Œåº”è¯¥å‘½ä¸­ç¼“å­˜
      'æ¯”è¾ƒPythonå’ŒNode.jsçš„ä¼˜ç¼ºç‚¹'
    ];
    
    for (const prompt of testPrompts) {
      console.log(`\nğŸ“ Prompt: ${prompt.substring(0, 40)}...`);
      const result = await pipeline.infer(prompt);
      console.log(`   Response: ${result.text.substring(0, 50)}...`);
      console.log(`   Cached: ${result.cached}, Model: ${result.modelKey || 'unknown'}`);
    }
    
    console.log('\n=== Statistics ===');
    console.log(JSON.stringify(pipeline.getStats(), null, 2));
    
  })();
}
