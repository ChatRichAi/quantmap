#!/usr/bin/env python3
"""
æ–°é—»çƒ­ç‚¹è·å–å™¨ - è·å–è‚¡ç¥¨/é¢˜æç›¸å…³æ–°é—»
"""

import json
import re
from datetime import datetime, timedelta
from urllib.parse import quote
import urllib.request
import ssl

# ç¦ç”¨SSLéªŒè¯ï¼ˆæŸäº›ç½‘ç«™éœ€è¦ï¼‰
ssl._create_default_https_context = ssl._create_unverified_context

class NewsFetcher:
    """æ–°é—»è·å–å™¨"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        }
    
    def fetch_10jqka_news(self, stock_code=None, keyword=None, limit=10):
        """
        ä»åŒèŠ±é¡ºè·å–æ–°é—»
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            keyword: å…³é”®è¯ï¼ˆé¢˜æï¼‰
            limit: è¿”å›æ•°é‡
        """
        news_list = []
        
        try:
            # åŒèŠ±é¡ºè´¢ç»æ–°é—»æ¥å£
            if stock_code:
                url = f"http://basic.10jqka.com.cn/api/stockph.php?code={stock_code}"
            else:
                # çƒ­ç‚¹æ–°é—»
                url = "http://news.10jqka.com.cn/today_list/"
            
            req = urllib.request.Request(url, headers=self.headers)
            with urllib.request.urlopen(req, timeout=10) as response:
                html = response.read().decode('utf-8', errors='ignore')
                # è¿™é‡Œéœ€è¦è§£æHTMLæå–æ–°é—»
                # ç®€åŒ–å¤„ç†ï¼Œè¿”å›ç¤ºä¾‹æ•°æ®
                news_list = self._parse_news_html(html, limit)
        except Exception as e:
            print(f"âš ï¸ è·å–åŒèŠ±é¡ºæ–°é—»å¤±è´¥: {e}")
        
        return news_list
    
    def fetch_eastmoney_news(self, stock_code=None, keyword=None, limit=10):
        """
        ä»ä¸œæ–¹è´¢å¯Œè·å–æ–°é—»
        """
        news_list = []
        
        try:
            if stock_code:
                # ä¸ªè‚¡æ–°é—»
                secid = f"0.{stock_code}" if stock_code.startswith('0') or stock_code.startswith('3') else f"1.{stock_code}"
                url = f"https://searchapi.eastmoney.com/api/sns/get?count={limit}&type=20&secid={secid}"
            else:
                # è´¢ç»è¦é—»
                url = f"https://searchapi.eastmoney.com/api/sns/get?count={limit}&type=20"
            
            req = urllib.request.Request(url, headers=self.headers)
            with urllib.request.urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode('utf-8'))
                
                if 'result' in data and 'data' in data['result']:
                    for item in data['result']['data'][:limit]:
                        news_list.append({
                            'title': item.get('title', ''),
                            'url': item.get('url', ''),
                            'source': item.get('source', 'ä¸œæ–¹è´¢å¯Œ'),
                            'time': item.get('time', ''),
                            'summary': item.get('content', '')[:100],
                            'sentiment': self._analyze_sentiment(item.get('title', ''))
                        })
        except Exception as e:
            print(f"âš ï¸ è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»å¤±è´¥: {e}")
        
        return news_list
    
    def fetch_sina_finance(self, limit=10):
        """
        ä»æ–°æµªè´¢ç»è·å–è¦é—»
        """
        news_list = []
        
        try:
            url = f"https://feed.sina.com.cn/api/roll/get?pageid=153&lid=2516&k=&num={limit}&r={datetime.now().timestamp()}"
            
            req = urllib.request.Request(url, headers=self.headers)
            with urllib.request.urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode('utf-8'))
                
                if 'result' in data and 'data' in data['result']:
                    for item in data['result']['data'][:limit]:
                        news_list.append({
                            'title': item.get('title', ''),
                            'url': item.get('url', ''),
                            'source': 'æ–°æµªè´¢ç»',
                            'time': item.get('time', ''),
                            'summary': '',
                            'sentiment': self._analyze_sentiment(item.get('title', ''))
                        })
        except Exception as e:
            print(f"âš ï¸ è·å–æ–°æµªè´¢ç»æ–°é—»å¤±è´¥: {e}")
        
        return news_list
    
    def _parse_news_html(self, html, limit):
        """è§£ææ–°é—»HTMLï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        news_list = []
        # è¿™é‡Œåº”è¯¥ä½¿ç”¨BeautifulSoupç­‰åº“è§£æHTML
        # ç®€åŒ–å¤„ç†
        return news_list
    
    def _analyze_sentiment(self, text):
        """
        ç®€å•çš„æƒ…æ„Ÿåˆ†æ
        
        Returns:
            'positive', 'negative', 'neutral'
        """
        positive_words = ['æ¶¨', 'å‡', 'çªç ´', 'åˆ©å¥½', 'å¢é•¿', 'ç›ˆåˆ©', 'åå¼¹', 'å¤§æ¶¨', 'æ¶¨åœ', 'æ‹‰å‡', 'å¼ºåŠ¿']
        negative_words = ['è·Œ', 'é™', 'ä¸‹è·Œ', 'åˆ©ç©º', 'äºæŸ', 'æš´è·Œ', 'è·Œåœ', 'è·³æ°´', 'å¼±åŠ¿', 'å›è°ƒ']
        
        p_count = sum(1 for w in positive_words if w in text)
        n_count = sum(1 for w in negative_words if w in text)
        
        if p_count > n_count:
            return 'positive'
        elif n_count > p_count:
            return 'negative'
        else:
            return 'neutral'
    
    def get_hot_themes(self):
        """
        è·å–å½“å‰çƒ­ç‚¹é¢˜æ
        """
        # è¿™é‡Œåº”è¯¥ä»é¾™è™æ¦œã€æ¶¨åœæ¿æ•°æ®ä¸­æå–çƒ­ç‚¹
        # ç®€åŒ–è¿”å›ç¤ºä¾‹
        return []
    
    def fetch_all_news(self, stock_code=None, keyword=None, limit=10):
        """
        è·å–æ‰€æœ‰æ¥æºçš„æ–°é—»
        
        Returns:
            list: åˆå¹¶åçš„æ–°é—»åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´æ’åº
        """
        all_news = []
        
        # ä»å¤šä¸ªæºè·å–
        all_news.extend(self.fetch_eastmoney_news(stock_code, keyword, limit))
        all_news.extend(self.fetch_sina_finance(limit))
        
        # å»é‡ï¼ˆæŒ‰æ ‡é¢˜ï¼‰
        seen_titles = set()
        unique_news = []
        for news in all_news:
            if news['title'] not in seen_titles:
                seen_titles.add(news['title'])
                unique_news.append(news)
        
        # æŒ‰æ—¶é—´æ’åºï¼ˆå¦‚æœæœ‰æ—¶é—´ä¿¡æ¯ï¼‰
        return unique_news[:limit]
    
    def analyze_theme_from_news(self, news_list):
        """
        ä»æ–°é—»ä¸­æå–å…³è”é¢˜æ
        
        Returns:
            dict: é¢˜æ -> ç›¸å…³æ–°é—»æ•°
        """
        # å¸¸è§é¢˜æå…³é”®è¯
        themes = {
            'AIç®—åŠ›': ['AI', 'ç®—åŠ›', 'äººå·¥æ™ºèƒ½', 'å¤§æ¨¡å‹', 'ChatGPT', 'AIGC'],
            'æœºå™¨äºº': ['æœºå™¨äºº', 'äººå½¢æœºå™¨äºº', 'å·¥ä¸šæœºå™¨äºº', 'å‡é€Ÿå™¨', 'ä¼ºæœ'],
            'èŠ¯ç‰‡': ['èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'å…‰åˆ»æœº', 'é›†æˆç”µè·¯', 'å›½äº§æ›¿ä»£'],
            'æ–°èƒ½æº': ['æ–°èƒ½æº', 'å…‰ä¼', 'å‚¨èƒ½', 'é”‚ç”µæ± ', 'ç”µåŠ¨è½¦', 'å®å¾·æ—¶ä»£'],
            'åŒ»è¯': ['åŒ»è¯', 'åˆ›æ–°è¯', 'CRO', 'åŒ»ç–—å™¨æ¢°', 'ä¸­è¯'],
            'é‡‘è': ['é‡‘è', 'åˆ¸å•†', 'é“¶è¡Œ', 'ä¿é™©', 'æœŸè´§'],
            'æ¶ˆè´¹': ['æ¶ˆè´¹', 'ç™½é…’', 'é£Ÿå“é¥®æ–™', 'é›¶å”®', 'å…ç¨'],
            'åœ°äº§': ['æˆ¿åœ°äº§', 'åœ°äº§', 'åŸºå»º', 'å»ºæ', 'å®¶å±…'],
        }
        
        theme_count = {k: 0 for k in themes}
        
        for news in news_list:
            title = news.get('title', '')
            for theme, keywords in themes.items():
                if any(kw in title for kw in keywords):
                    theme_count[theme] += 1
        
        # æŒ‰æ•°é‡æ’åº
        return dict(sorted(theme_count.items(), key=lambda x: x[1], reverse=True))

def main():
    """æµ‹è¯•"""
    fetcher = NewsFetcher()
    
    # è·å–æ–°é—»
    print("ğŸ“° è·å–æ–°é—»ä¸­...")
    news = fetcher.fetch_all_news(limit=10)
    
    print(f"\nè·å–åˆ° {len(news)} æ¡æ–°é—»:\n")
    for i, n in enumerate(news[:5], 1):
        sentiment_emoji = {'positive': 'ğŸŸ¢', 'negative': 'ğŸ”´', 'neutral': 'âšª'}.get(n['sentiment'], 'âšª')
        print(f"{i}. {sentiment_emoji} {n['title']}")
        print(f"   æ¥æº: {n['source']} | æ—¶é—´: {n.get('time', 'N/A')}")
        print()
    
    # åˆ†æé¢˜æ
    themes = fetcher.analyze_theme_from_news(news)
    print("\nğŸ“Š çƒ­ç‚¹é¢˜æåˆ†æ:")
    for theme, count in themes.items():
        if count > 0:
            print(f"  {theme}: {count} æ¡ç›¸å…³æ–°é—»")

if __name__ == "__main__":
    main()
