"""
QuantClaw Pro - å¤šæ—¶é—´ç»´åº¦åˆ†æç³»ç»Ÿ
æ•´åˆ 15åˆ†é’Ÿ / 1å°æ—¶ / 4å°æ—¶ / 1å¤© æ•°æ®
æ•æ‰è‚¡ç¥¨åœ¨ä¸åŒæ—¶é—´å°ºåº¦çš„"æ€§æ ¼"
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TimeFrame(Enum):
    """æ—¶é—´ç»´åº¦æšä¸¾"""
    M15 = "15m"      # 15åˆ†é’Ÿ
    H1 = "1h"        # 1å°æ—¶
    H4 = "4h"        # 4å°æ—¶
    D1 = "1d"        # 1å¤©


@dataclass
class MultiTimeframeFeatures:
    """å¤šæ—¶é—´ç»´åº¦ç‰¹å¾"""
    m15_features: Optional[Dict[str, float]] = None
    h1_features: Optional[Dict[str, float]] = None
    h4_features: Optional[Dict[str, float]] = None
    d1_features: Optional[Dict[str, float]] = None
    
    def get_available_timeframes(self) -> List[TimeFrame]:
        """è·å–å¯ç”¨çš„æ—¶é—´ç»´åº¦"""
        available = []
        if self.m15_features:
            available.append(TimeFrame.M15)
        if self.h1_features:
            available.append(TimeFrame.H1)
        if self.h4_features:
            available.append(TimeFrame.H4)
        if self.d1_features:
            available.append(TimeFrame.D1)
        return available


class MultiTimeframeDataSource:
    """
    å¤šæ—¶é—´ç»´åº¦æ•°æ®æº
    è·å– 15m/1h/4h/1d æ•°æ®
    """
    
    # yfinance æ”¯æŒçš„é—´éš”æ˜ å°„
    INTERVAL_MAP = {
        TimeFrame.M15: "15m",
        TimeFrame.H1: "1h",
        TimeFrame.H4: "1h",  # yfinanceä¸æ”¯æŒ4hï¼Œéœ€è¦ä»1hèšåˆ
        TimeFrame.D1: "1d"
    }
    
    # æ•°æ®å‘¨æœŸï¼ˆéœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®ï¼‰
    PERIOD_MAP = {
        TimeFrame.M15: "1mo",   # 15åˆ†é’Ÿéœ€è¦1ä¸ªæœˆ
        TimeFrame.H1: "3mo",    # 1å°æ—¶éœ€è¦3ä¸ªæœˆ
        TimeFrame.H4: "6mo",    # 4å°æ—¶éœ€è¦6ä¸ªæœˆ
        TimeFrame.D1: "1y"      # 1å¤©éœ€è¦1å¹´
    }
    
    def __init__(self):
        self.cache: Dict[str, pd.DataFrame] = {}
    
    def fetch_multi_timeframe(self, ticker: str) -> Dict[TimeFrame, Optional[pd.DataFrame]]:
        """
        è·å–å¤šæ—¶é—´ç»´åº¦æ•°æ®
        
        Returns:
            {TimeFrame: DataFrame} å­—å…¸
        """
        results = {}
        
        try:
            import yfinance as yf
            
            # è·å–æ—¥çº¿æ•°æ®
            logger.info(f"Fetching daily data for {ticker}...")
            daily = yf.download(ticker, period=self.PERIOD_MAP[TimeFrame.D1], 
                               interval=self.INTERVAL_MAP[TimeFrame.D1], 
                               progress=False)
            if not daily.empty:
                # å¤„ç†å¤šçº§åˆ—å
                if isinstance(daily.columns, pd.MultiIndex):
                    daily.columns = [c[0].lower().replace(' ', '_') for c in daily.columns]
                else:
                    daily.columns = [c.lower().replace(' ', '_') for c in daily.columns]
                results[TimeFrame.D1] = daily
            
            # è·å–1å°æ—¶æ•°æ®ï¼ˆç”¨äº4å°æ—¶èšåˆï¼‰
            logger.info(f"Fetching hourly data for {ticker}...")
            hourly = yf.download(ticker, period="1mo", interval="1h", progress=False)
            if not hourly.empty:
                # å¤„ç†å¤šçº§åˆ—å
                if isinstance(hourly.columns, pd.MultiIndex):
                    hourly.columns = [c[0].lower().replace(' ', '_') for c in hourly.columns]
                else:
                    hourly.columns = [c.lower().replace(' ', '_') for c in hourly.columns]
                results[TimeFrame.H1] = hourly
                
                # èšåˆä¸º4å°æ—¶æ•°æ®
                h4_data = self._aggregate_to_4h(hourly)
                if h4_data is not None:
                    results[TimeFrame.H4] = h4_data
            
            # è·å–15åˆ†é’Ÿæ•°æ®
            logger.info(f"Fetching 15-min data for {ticker}...")
            m15 = yf.download(ticker, period="5d", interval="15m", progress=False)
            if not m15.empty:
                # å¤„ç†å¤šçº§åˆ—å
                if isinstance(m15.columns, pd.MultiIndex):
                    m15.columns = [c[0].lower().replace(' ', '_') for c in m15.columns]
                else:
                    m15.columns = [c.lower().replace(' ', '_') for c in m15.columns]
                results[TimeFrame.M15] = m15
            
        except Exception as e:
            logger.error(f"Error fetching multi-timeframe data: {e}")
        
        return results
    
    def _aggregate_to_4h(self, hourly_df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """å°†1å°æ—¶æ•°æ®èšåˆä¸º4å°æ—¶æ•°æ®"""
        try:
            # æ¯4å°æ—¶èšåˆ
            df = hourly_df.copy()
            df['hour_group'] = (df.index.hour // 4) * 4
            
            # æŒ‰æ—¥æœŸå’Œå°æ—¶ç»„èšåˆ
            agg_dict = {
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            }
            
            # é‡æ–°é‡‡æ ·ä¸º4å°æ—¶
            h4 = df.resample('4h').agg(agg_dict).dropna()
            return h4
        except Exception as e:
            logger.error(f"Error aggregating to 4h: {e}")
            return None


class MultiTimeframeFeatureExtractor:
    """
    å¤šæ—¶é—´ç»´åº¦ç‰¹å¾æå–å™¨
    ä»ä¸åŒæ—¶é—´å°ºåº¦æå–ç‰¹å¾
    """
    
    def __init__(self):
        self.perception = None  # å°†åœ¨å¯¼å…¥ååˆå§‹åŒ–
        
    def extract_all_timeframes(self, 
                               ticker: str,
                               data_dict: Dict[TimeFrame, pd.DataFrame],
                               lookback_periods: Optional[Dict[TimeFrame, int]] = None
                               ) -> MultiTimeframeFeatures:
        """
        ä»æ‰€æœ‰å¯ç”¨æ—¶é—´ç»´åº¦æå–ç‰¹å¾
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            data_dict: {TimeFrame: DataFrame} å­—å…¸
            lookback_periods: å„æ—¶é—´ç»´åº¦çš„å›çœ‹å‘¨æœŸæ•°
            
        Returns:
            MultiTimeframeFeatures å¯¹è±¡
        """
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
        from perception_layer import PerceptionLayer
        self.perception = PerceptionLayer()
        
        if lookback_periods is None:
            lookback_periods = {
                TimeFrame.M15: 96,    # 15åˆ†é’Ÿ: 96ä¸ªå‘¨æœŸ = 1å¤©
                TimeFrame.H1: 168,    # 1å°æ—¶: 168ä¸ªå‘¨æœŸ = 1å‘¨
                TimeFrame.H4: 30,     # 4å°æ—¶: 30ä¸ªå‘¨æœŸ = 5å¤©
                TimeFrame.D1: 60      # 1å¤©: 60ä¸ªå‘¨æœŸ = 2ä¸ªæœˆ
            }
        
        features = MultiTimeframeFeatures()
        
        for tf, df in data_dict.items():
            if df is None or len(df) < lookback_periods[tf]:
                logger.warning(f"Insufficient data for {tf.value}: {len(df) if df is not None else 0} bars")
                continue
            
            try:
                # æå–è¯¥æ—¶é—´ç»´åº¦çš„ç‰¹å¾
                lookback = lookback_periods[tf]
                feature_data = df.tail(lookback)
                
                feature_vector = self.perception.extract_features(
                    ticker=f"{ticker}_{tf.value}",
                    df=feature_data
                )
                
                # æ·»åŠ æ—¶é—´ç»´åº¦å‰ç¼€
                prefixed_features = {f"{tf.value}_{k}": v 
                                   for k, v in feature_vector.feature_dict.items()}
                
                if tf == TimeFrame.M15:
                    features.m15_features = prefixed_features
                elif tf == TimeFrame.H1:
                    features.h1_features = prefixed_features
                elif tf == TimeFrame.H4:
                    features.h4_features = prefixed_features
                elif tf == TimeFrame.D1:
                    features.d1_features = prefixed_features
                
                logger.info(f"Extracted {len(prefixed_features)} features from {tf.value}")
                
            except Exception as e:
                logger.error(f"Error extracting features for {tf.value}: {e}")
        
        return features


class MultiTimeframePersonalityAnalyzer:
    """
    å¤šæ—¶é—´ç»´åº¦æ€§æ ¼åˆ†æå™¨
    èåˆå¤šä¸ªæ—¶é—´ç»´åº¦çš„ç‰¹å¾è¿›è¡Œç»¼åˆåˆ¤æ–­
    """
    
    # æ—¶é—´ç»´åº¦æƒé‡ï¼ˆå¯æ ¹æ®ç»éªŒè°ƒæ•´ï¼‰
    TIMEFRAME_WEIGHTS = {
        TimeFrame.M15: 0.15,   # 15åˆ†é’Ÿ: çŸ­æœŸæƒ…ç»ª
        TimeFrame.H1: 0.25,    # 1å°æ—¶: æ—¥å†…è¶‹åŠ¿
        TimeFrame.H4: 0.30,    # 4å°æ—¶: æ—¥é—´è¶‹åŠ¿ï¼ˆæœ€é‡è¦ï¼‰
        TimeFrame.D1: 0.30     # 1å¤©: é•¿æœŸç»“æ„
    }
    
    # å„æ—¶é—´ç»´åº¦å…³æ³¨çš„ç‰¹å¾
    TIMEFRAME_FOCUS = {
        TimeFrame.M15: ['volatility', 'volume_price_corr', 'rsi_extreme_freq'],
        TimeFrame.H1: ['adx', 'trend_slope', 'ma_alignment'],
        TimeFrame.H4: ['hurst_exponent', 'direction_consistency', 'trend_efficiency'],
        TimeFrame.D1: ['market_correlation', 'support_distance', 'consolidation_ratio']
    }
    
    def __init__(self):
        self.cognition = None  # å»¶è¿Ÿå¯¼å…¥
    
    def analyze(self, ticker: str, mtf_features: MultiTimeframeFeatures) -> Dict:
        """
        å¤šç»´åº¦ç»¼åˆåˆ†æ
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            mtf_features: å¤šæ—¶é—´ç»´åº¦ç‰¹å¾
            
        Returns:
            ç»¼åˆåˆ†æç»“æœ
        """
        from cognition_layer import CognitionLayer
        self.cognition = CognitionLayer()
        
        # 1. åˆ†åˆ«åˆ†æå„æ—¶é—´ç»´åº¦
        timeframe_results = {}
        
        for tf in mtf_features.get_available_timeframes():
            # è·å–æ­£ç¡®çš„å±æ€§å
            attr_map = {
                TimeFrame.M15: 'm15_features',
                TimeFrame.H1: 'h1_features',
                TimeFrame.H4: 'h4_features',
                TimeFrame.D1: 'd1_features'
            }
            attr_name = attr_map.get(tf)
            if not attr_name:
                continue
                
            features = getattr(mtf_features, attr_name)
            if features:
                # ç§»é™¤æ—¶é—´ç»´åº¦å‰ç¼€ç”¨äºåˆ†æ
                clean_features = {k.replace(f"{tf.value}_", ""): v 
                                for k, v in features.items()}
                
                profile = self.cognition.classifier.classify(ticker, clean_features)
                timeframe_results[tf] = {
                    'mbti': profile.mbti_type.value,
                    'dimensions': profile.dimension_scores.to_dict(),
                    'confidence': profile.confidence
                }
        
        # 2. èåˆå„æ—¶é—´ç»´åº¦çš„å››ç»´åˆ†æ•°
        fused_dimensions = self._fuse_dimensions(timeframe_results)
        
        # 3. åŸºäºèåˆåçš„ç»´åº¦é‡æ–°åˆ†ç±»
        fused_profile = self.cognition.classifier.classify(ticker, fused_dimensions)
        
        # 4. æ£€æµ‹æ—¶é—´ç»´åº¦ä¸€è‡´æ€§ï¼ˆå…±æŒ¯/èƒŒç¦»ï¼‰
        consistency = self._analyze_timeframe_consistency(timeframe_results)
        
        return {
            'ticker': ticker,
            'fused_personality': {
                'mbti_type': fused_profile.mbti_type.value,
                'mbti_name': fused_profile.mbti_name,
                'category': fused_profile.category,
                'risk_level': fused_profile.risk_level,
                'confidence': fused_profile.confidence,
                'dimensions': fused_profile.dimension_scores.to_dict()
            },
            'timeframe_details': timeframe_results,
            'consistency_analysis': consistency,
            'trading_implications': self._generate_implications(consistency)
        }
    
    def _fuse_dimensions(self, timeframe_results: Dict) -> Dict[str, float]:
        """
        èåˆå„æ—¶é—´ç»´åº¦çš„å››ç»´åˆ†æ•°
        
        ä½¿ç”¨åŠ æƒå¹³å‡ï¼Œä¸åŒæ—¶é—´ç»´åº¦æœ‰ä¸åŒçš„æƒé‡
        """
        fused = {'ie': 0, 'ns': 0, 'tf': 0, 'jp': 0}
        total_weight = 0
        
        for tf, result in timeframe_results.items():
            weight = self.TIMEFRAME_WEIGHTS.get(tf, 0.25)
            dims = result['dimensions']
            
            fused['ie'] += dims['ie'] * weight
            fused['ns'] += dims['ns'] * weight
            fused['tf'] += dims['tf'] * weight
            fused['jp'] += dims['jp'] * weight
            total_weight += weight
        
        # å½’ä¸€åŒ–
        if total_weight > 0:
            for key in fused:
                fused[key] /= total_weight
        
        return fused
    
    def _analyze_timeframe_consistency(self, timeframe_results: Dict) -> Dict:
        """
        åˆ†ææ—¶é—´ç»´åº¦ä¸€è‡´æ€§
        
        æ£€æµ‹æ˜¯å¦å­˜åœ¨å¤šå‘¨æœŸå…±æŒ¯æˆ–èƒŒç¦»
        """
        if len(timeframe_results) < 2:
            return {'status': 'insufficient_data'}
        
        # æå–å„æ—¶é—´ç»´åº¦çš„MBTIç±»å‹
        mbti_types = [r['mbti'] for r in timeframe_results.values()]
        
        # æ£€æŸ¥æ˜¯å¦ä¸€è‡´
        if len(set(mbti_types)) == 1:
            consistency = 'perfect_alignment'  # å®Œå…¨ä¸€è‡´
        elif len(set(mbti_types)) == 2:
            consistency = 'partial_alignment'  # éƒ¨åˆ†ä¸€è‡´
        else:
            consistency = 'divergence'  # èƒŒç¦»
        
        # åˆ†æå››ç»´ä¸€è‡´æ€§
        dimension_variance = {}
        for dim in ['ie', 'ns', 'tf', 'jp']:
            values = [r['dimensions'][dim] for r in timeframe_results.values()]
            variance = np.var(values)
            dimension_variance[dim] = {
                'variance': variance,
                'consistency': 'high' if variance < 0.05 else ('medium' if variance < 0.1 else 'low')
            }
        
        return {
            'status': consistency,
            'mbti_types_by_timeframe': {tf.value: r['mbti'] 
                                        for tf, r in timeframe_results.items()},
            'dimension_variance': dimension_variance,
            'recommendation': self._consistency_recommendation(consistency)
        }
    
    def _consistency_recommendation(self, status: str) -> str:
        """æ ¹æ®ä¸€è‡´æ€§ç»™å‡ºå»ºè®®"""
        recommendations = {
            'perfect_alignment': 'å¤šå‘¨æœŸå…±æŒ¯ï¼Œä¿¡å·å¼ºï¼Œå¯å¤§èƒ†æ‰§è¡Œç­–ç•¥',
            'partial_alignment': 'éƒ¨åˆ†å…±æŒ¯ï¼Œä¿¡å·ä¸­ç­‰ï¼Œé€‚å½“ä»“ä½å‚ä¸',
            'divergence': 'å¤šå‘¨æœŸèƒŒç¦»ï¼Œä¿¡å·æ··ä¹±ï¼Œå»ºè®®è§‚æœ›æˆ–é™ä½ä»“ä½',
            'insufficient_data': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­å¤šå‘¨æœŸä¸€è‡´æ€§'
        }
        return recommendations.get(status, 'æœªçŸ¥')
    
    def _generate_implications(self, consistency: Dict) -> List[str]:
        """ç”Ÿæˆäº¤æ˜“å¯ç¤º"""
        implications = []
        
        status = consistency.get('status')
        
        if status == 'perfect_alignment':
            implications.extend([
                'âœ“ å¤šå‘¨æœŸæ–¹å‘ä¸€è‡´ï¼Œè¶‹åŠ¿ç¡®è®¤åº¦é«˜',
                'âœ“ å¯ä»¥ä½¿ç”¨æ ‡å‡†ä»“ä½æˆ–åŠ ä»“',
                'âœ“ æ­¢æŸå¯ä»¥é€‚å½“æ”¾å®½'
            ])
        elif status == 'partial_alignment':
            implications.extend([
                'â–³ éƒ¨åˆ†å‘¨æœŸç¡®è®¤ï¼Œè¶‹åŠ¿æœ‰å¾…è§‚å¯Ÿ',
                'â–³ ä½¿ç”¨æ ‡å‡†ä»“ä½æˆ–é™ä½ä»“ä½',
                'â–³ ä¸¥æ ¼æ‰§è¡Œæ­¢æŸ'
            ])
        elif status == 'divergence':
            implications.extend([
                'âœ— å¤šå‘¨æœŸå†²çªï¼Œå¸‚åœºå¤„äºéœ‡è¡æˆ–è½¬æŠ˜',
                'âœ— é™ä½ä»“ä½æˆ–è§‚æœ›',
                'âœ— ç¼©çŸ­æŒä»“å‘¨æœŸï¼Œå¿«è¿›å¿«å‡º'
            ])
        
        # æ£€æŸ¥å…·ä½“ç»´åº¦çš„ä¸€è‡´æ€§
        dim_var = consistency.get('dimension_variance', {})
        
        if dim_var.get('ns', {}).get('consistency') == 'low':
            implications.append('âš  è¶‹åŠ¿ç»´åº¦(N/S)åˆ†æ­§å¤§ï¼Œæ–¹å‘ä¸æ˜æœ—')
        
        if dim_var.get('jp', {}).get('consistency') == 'low':
            implications.append('âš  åˆ¤æ–­ç»´åº¦(J/P)åˆ†æ­§å¤§ï¼Œå¸‚åœºçŠ¹è±«')
        
        return implications


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

def demo_multi_timeframe():
    """å¤šæ—¶é—´ç»´åº¦åˆ†ææ¼”ç¤º"""
    print("=" * 80)
    print("QuantClaw Pro - å¤šæ—¶é—´ç»´åº¦åˆ†ææ¼”ç¤º")
    print("=" * 80)
    print("\nåˆ†æç»´åº¦: 15åˆ†é’Ÿ / 1å°æ—¶ / 4å°æ—¶ / 1å¤©")
    print()
    
    # åˆå§‹åŒ–ç»„ä»¶
    data_source = MultiTimeframeDataSource()
    feature_extractor = MultiTimeframeFeatureExtractor()
    analyzer = MultiTimeframePersonalityAnalyzer()
    
    # é€‰æ‹©è‚¡ç¥¨
    tickers = ['AAPL', 'TSLA']
    
    for ticker in tickers:
        print(f"\n{'='*80}")
        print(f"ã€åˆ†æã€‘{ticker}")
        print('='*80)
        
        # 1. è·å–å¤šæ—¶é—´ç»´åº¦æ•°æ®
        print("\nğŸ“¥ è·å–å¤šæ—¶é—´ç»´åº¦æ•°æ®...")
        data_dict = data_source.fetch_multi_timeframe(ticker)
        
        available = [tf.value for tf, df in data_dict.items() if df is not None]
        print(f"  å¯ç”¨ç»´åº¦: {', '.join(available)}")
        
        if not available:
            print("  âŒ æ— å¯ç”¨æ•°æ®")
            continue
        
        # æ˜¾ç¤ºå„ç»´åº¦æ•°æ®é‡
        for tf, df in data_dict.items():
            if df is not None:
                print(f"  {tf.value}: {len(df)} æ ¹Kçº¿")
        
        # 2. æå–å¤šç»´åº¦ç‰¹å¾
        print("\nğŸ” æå–å¤šæ—¶é—´ç»´åº¦ç‰¹å¾...")
        mtf_features = feature_extractor.extract_all_timeframes(ticker, data_dict)
        
        # 3. å¤šç»´åº¦ç»¼åˆåˆ†æ
        print("\nğŸ§  å¤šç»´åº¦ç»¼åˆåˆ†æ...")
        result = analyzer.analyze(ticker, mtf_features)
        
        # æ˜¾ç¤ºç»“æœ
        fused = result['fused_personality']
        print(f"\n  èåˆæ€§æ ¼: {fused['mbti_type']} ({fused['mbti_name']})")
        print(f"  æ‰€å±ç±»åˆ«: {fused['category']}")
        print(f"  é£é™©ç­‰çº§: {fused['risk_level']}")
        print(f"  ç½®ä¿¡åº¦: {fused['confidence']:.2%}")
        
        dims = fused['dimensions']
        print(f"\n  èåˆå››ç»´åˆ†æ•°:")
        print(f"    I/E: {dims['ie']:.4f} ({'Eå¤–å‘' if dims['ie'] > 0.5 else 'Iå†…å‘'})")
        print(f"    N/S: {dims['ns']:.4f} ({'Nç›´è§‰' if dims['ns'] > 0.5 else 'Så®æ„Ÿ'})")
        print(f"    T/F: {dims['tf']:.4f} ({'Fæƒ…æ„Ÿ' if dims['tf'] > 0.5 else 'Tæ€è€ƒ'})")
        print(f"    J/P: {dims['jp']:.4f} ({'Jåˆ¤æ–­' if dims['jp'] > 0.5 else 'Pæ„ŸçŸ¥'})")
        
        # æ˜¾ç¤ºå„æ—¶é—´ç»´åº¦ç»†åˆ†
        print(f"\n  å„æ—¶é—´ç»´åº¦æ€§æ ¼:")
        for tf, details in result['timeframe_details'].items():
            print(f"    {tf.value:4s}: {details['mbti']} (ç½®ä¿¡åº¦: {details['confidence']:.1%})")
        
        # æ˜¾ç¤ºä¸€è‡´æ€§åˆ†æ
        consistency = result['consistency_analysis']
        print(f"\n  å¤šå‘¨æœŸä¸€è‡´æ€§: {consistency['status']}")
        print(f"  å»ºè®®: {consistency['recommendation']}")
        
        # æ˜¾ç¤ºäº¤æ˜“å¯ç¤º
        print(f"\n  äº¤æ˜“å¯ç¤º:")
        for impl in result['trading_implications']:
            print(f"    {impl}")
        
        # æ£€æŸ¥ç»´åº¦æ–¹å·®
        if 'dimension_variance' in consistency:
            print(f"\n  ç»´åº¦ä¸€è‡´æ€§åˆ†æ:")
            for dim, var in consistency['dimension_variance'].items():
                print(f"    {dim.upper()}: {var['consistency']} (æ–¹å·®: {var['variance']:.4f})")
    
    print(f"\n{'='*80}")
    print("å¤šæ—¶é—´ç»´åº¦åˆ†ææ¼”ç¤ºå®Œæˆ!")
    print("=" * 80)
    print("\nğŸ’¡ å¤šç»´åº¦ä¼˜åŠ¿:")
    print("  â€¢ 15åˆ†é’Ÿ: æ•æ‰æ—¥å†…æƒ…ç»ªå’ŒçŸ­æœŸæ³¢åŠ¨")
    print("  â€¢ 1å°æ—¶: è¯†åˆ«æ—¥å†…è¶‹åŠ¿å’Œæ”¯æ’‘é˜»åŠ›")
    print("  â€¢ 4å°æ—¶: ç¡®è®¤æ—¥é—´è¶‹åŠ¿æ–¹å‘")
    print("  â€¢ 1å¤©: åˆ¤æ–­é•¿æœŸç»“æ„å’Œä¸»è¦è¶‹åŠ¿")
    print("  â€¢ èåˆåˆ†æ: æ£€æµ‹å¤šå‘¨æœŸå…±æŒ¯/èƒŒç¦»ï¼Œæé«˜ä¿¡å·å¯é æ€§")


if __name__ == "__main__":
    demo_multi_timeframe()
