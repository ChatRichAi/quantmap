#!/usr/bin/env python3
"""
QuantGenius Nation - é‡åŒ–å¤©æ‰ä¹‹å›½
å…¨è‡ªåŠ¨è¿›åŒ–åŸºç¡€è®¾æ–½

æ¶æ„ï¼š
â”œâ”€â”€ ç´ ææŒ–æ˜å±‚ (Miners) - å¤šæºä¿¡æ¯æ‘„å…¥
â”œâ”€â”€ æ¨¡å¼æå–å±‚ (Extractors) - ä»å™ªå£°ä¸­æå–ç»“æ„
â”œâ”€â”€ åŸºå› å·¥ç¨‹å±‚ (Engineering) - è®¾è®¡ã€å˜å¼‚ã€é‡ç»„
â”œâ”€â”€ è‡ªç„¶é€‰æ‹©å±‚ (Selection) - æ®‹é…·æ·˜æ±°ï¼Œé€‚è€…ç”Ÿå­˜
â”œâ”€â”€ çŸ¥è¯†æ²‰æ·€å±‚ (Knowledge) - é•¿æœŸè®°å¿†ä¸ä¼ æ‰¿
â””â”€â”€ å…ƒè®¤çŸ¥å±‚ (Meta) - è‡ªæˆ‘ç›‘æ§ä¸ç­–ç•¥è°ƒæ•´
"""

import os
import sys
import json
import time
import schedule
import sqlite3
import threading
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Callable
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed

sys.path.insert(0, '/Users/oneday/.openclaw/workspace/quantclaw')


@dataclass
class EvolutionState:
    """ç³»ç»ŸçŠ¶æ€å¿«ç…§"""
    timestamp: datetime
    generation: int
    population: int
    gene_tiers: Dict[str, int]
    diversity_score: float
    recent_casualties: int
    recent_births: int
    top_performer: Optional[str]
    system_health: str  # healthy, stressed, critical


class DataSourceMiners:
    """
    å¤šæºç´ ææŒ–æ˜å™¨
    ä¸è®¾ä¸Šé™ï¼Œä¸è®¾ä¸‹é™ï¼Œåªè¦å¯èƒ½æœ‰ä»·å€¼å°±æŒ–
    """
    
    def __init__(self, config_path: str = None):
        self.config = self._load_config(config_path)
        self.mined_materials = []
        
    def _load_config(self, path):
        """åŠ è½½æ•°æ®æºé…ç½®"""
        default = {
            'arxiv': {'enabled': True, 'queries': [
                'factor investing', 'momentum strategy', 'mean reversion',
                'statistical arbitrage', 'volatility trading', 'machine learning trading',
                'quantitative strategy', 'algorithmic trading', 'pairs trading',
                'market microstructure', 'high frequency trading'
            ]},
            'github': {'enabled': True, 'queries': [
                'quantitative trading', 'backtesting', 'trading strategy',
                'technical analysis', 'algorithmic trading python'
            ]},
            'financial_blogs': {'enabled': False},  # éœ€è¦çˆ¬è™«
            'academic_databases': {'enabled': False},  # éœ€è¦ API key
            'trading_forums': {'enabled': False},  # éœ€è¦è§£æ
        }
        return default
    
    def mine_all(self) -> List[Dict]:
        """æ‰§è¡Œå…¨é‡æŒ–æ˜"""
        print("\n" + "="*70)
        print("â›ï¸  UNRESTRICTED DATA MINING")
        print("="*70)
        
        all_materials = []
        
        # 1. arXiv æŒ–æ˜
        if self.config['arxiv']['enabled']:
            materials = self._mine_arxiv()
            all_materials.extend(materials)
        
        # 2. GitHub æŒ–æ˜
        if self.config['github']['enabled']:
            materials = self._mine_github()
            all_materials.extend(materials)
        
        # 3. æœ¬åœ°çŸ¥è¯†åº“æŒ–æ˜
        materials = self._mine_local_knowledge()
        all_materials.extend(materials)
        
        # 4. å¸‚åœºæ•°æ®æ¨¡å¼æŒ–æ˜
        materials = self._mine_market_patterns()
        all_materials.extend(materials)
        
        print(f"\nâœ… Total materials mined: {len(all_materials)}")
        return all_materials
    
    def _mine_arxiv(self) -> List[Dict]:
        """æŒ–æ˜ arXiv"""
        print("\nğŸ“š Mining arXiv...")
        
        from arxiv_gene_extractor import ArXivAPI
        
        api = ArXivAPI()
        materials = []
        
        for query in self.config['arxiv']['queries']:
            try:
                papers = api.search(query, max_results=30)
                for paper in papers:
                    materials.append({
                        'source': 'arxiv',
                        'source_id': paper['id'],
                        'title': paper['title'],
                        'content': paper.get('summary', ''),
                        'metadata': {
                            'categories': paper.get('categories', []),
                            'published': paper.get('published', ''),
                            'query': query
                        },
                        'mined_at': datetime.now().isoformat()
                    })
                print(f"   {query}: {len(papers)} papers")
                time.sleep(1)  # ç¤¼è²Œå»¶è¿Ÿ
            except Exception as e:
                print(f"   âŒ {query}: {e}")
        
        return materials
    
    def _mine_github(self) -> List[Dict]:
        """æŒ–æ˜ GitHub é‡åŒ–é¡¹ç›®"""
        print("\nğŸ’» Mining GitHub...")
        
        materials = []
        
        # ä½¿ç”¨ GitHub API æœç´¢
        for query in self.config['github']['queries']:
            try:
                # ç®€å•å®ç°ï¼šä½¿ç”¨ gh CLI
                result = subprocess.run(
                    ['gh', 'search', 'repos', query, '--limit', '20', '--json', 'name,description,url,readme'],
                    capture_output=True, text=True, timeout=30
                )
                
                if result.returncode == 0:
                    repos = json.loads(result.stdout)
                    for repo in repos:
                        materials.append({
                            'source': 'github',
                            'source_id': repo.get('url', ''),
                            'title': repo.get('name', ''),
                            'content': repo.get('description', ''),
                            'metadata': {
                                'readme': repo.get('readme', '')[:2000],
                                'query': query
                            },
                            'mined_at': datetime.now().isoformat()
                        })
                    print(f"   {query}: {len(repos)} repos")
                else:
                    print(f"   âš ï¸  gh CLI error: {result.stderr[:100]}")
                    
            except Exception as e:
                print(f"   âŒ {query}: {e}")
        
        return materials
    
    def _mine_local_knowledge(self) -> List[Dict]:
        """æŒ–æ˜æœ¬åœ°çŸ¥è¯†åº“"""
        print("\nğŸ“‚ Mining local knowledge...")
        
        materials = []
        memory_path = Path('/Users/oneday/.openclaw/workspace/memory')
        
        # æ‰«æè®°å¿†æ–‡ä»¶
        for md_file in memory_path.rglob('*.md'):
            try:
                content = md_file.read_text(encoding='utf-8')
                if len(content) > 100:  # è¿‡æ»¤ç©ºæ–‡ä»¶
                    materials.append({
                        'source': 'local_memory',
                        'source_id': str(md_file.relative_to(memory_path)),
                        'title': md_file.stem,
                        'content': content[:5000],  # é™åˆ¶é•¿åº¦
                        'metadata': {
                            'path': str(md_file),
                            'size': len(content)
                        },
                        'mined_at': datetime.now().isoformat()
                    })
            except:
                pass
        
        print(f"   Local files: {len(materials)}")
        return materials
    
    def _mine_market_patterns(self) -> List[Dict]:
        """ä»å¸‚åœºæ•°æ®æŒ–æ˜æ¨¡å¼"""
        print("\nğŸ“ˆ Mining market patterns...")
        
        materials = []
        
        # è¿™é‡Œå¯ä»¥æ¥å…¥å®æ—¶å¸‚åœºæ•°æ®æŒ–æ˜
        # æš‚æ—¶ä½¿ç”¨å·²æœ‰åˆ†æç»“æœ
        state_files = [
            '/Users/oneday/.openclaw/workspace/memory/state/a-share-state.json',
            '/Users/oneday/.openclaw/workspace/memory/state/us-stock-state.json',
            '/Users/oneday/.openclaw/workspace/memory/state/crypto-state.json'
        ]
        
        for state_file in state_files:
            try:
                with open(state_file) as f:
                    data = json.load(f)
                    materials.append({
                        'source': 'market_state',
                        'source_id': state_file,
                        'title': f"Market State: {data.get('market', 'unknown')}",
                        'content': json.dumps(data, indent=2),
                        'metadata': data,
                        'mined_at': datetime.now().isoformat()
                    })
            except:
                pass
        
        print(f"   Market states: {len(materials)}")
        return materials


class PatternRecognitionEngine:
    """
    æ¨¡å¼è¯†åˆ«å¼•æ“
    ä»åŸå§‹ç´ æä¸­æå–å¯å¤ç”¨çš„ç­–ç•¥æ¨¡å¼
    """
    
    # æ‰©å±•çš„æ¨¡å¼åº“
    PATTERN_LIBRARY = {
        # ä»·æ ¼è¡Œä¸ºæ¨¡å¼
        'breakout_patterns': {
            'keywords': ['breakout', 'çªç ´', 'break through', 'penetrates'],
            'logic': 'PRICE_THRESHOLD AND CONFIRMATION',
            'variations': ['volume_confirm', 'time_confirm', 'multi_tf_confirm']
        },
        'reversal_patterns': {
            'keywords': ['reversal', 'revert', 'åè½¬', 'mean reversion'],
            'logic': 'EXTREME_DEVIATION AND REVERSION_SIGNAL',
            'variations': ['rsi_extreme', 'bollinger_extreme', 'zscore_extreme']
        },
        'trend_following': {
            'keywords': ['trend', 'momentum', 'è¶‹åŠ¿', 'åŠ¨é‡'],
            'logic': 'TREND_ALIGN AND ENTRY_TRIGGER',
            'variations': ['ma_cross', 'macd_signal', 'adx_filter']
        },
        'volatility_strategies': {
            'keywords': ['volatility', 'æ³¢åŠ¨', 'garch', 'realized vol'],
            'logic': 'VOLATILITY_REGIME AND POSITION_SIZING',
            'variations': ['vol_target', 'vol_filter', 'vol_expansion']
        },
        'statistical_arbitrage': {
            'keywords': ['cointegration', 'pair trading', 'å‡å€¼å›å¤', 'ç»Ÿè®¡å¥—åˆ©'],
            'logic': 'COINTEGRATION AND DEVIATION',
            'variations': ['pair_selection', 'spread_zscore', 'half_life']
        },
        'machine_learning': {
            'keywords': ['machine learning', 'ml', 'prediction', 'classification'],
            'logic': 'FEATURE_SET AND MODEL_PREDICTION',
            'variations': ['supervised', 'unsupervised', 'reinforcement']
        },
        'market_microstructure': {
            'keywords': ['microstructure', 'order flow', 'liquidity', 'spread'],
            'logic': 'ORDER_FLOW_ANALYSIS AND EXECUTION',
            'variations': ['imbalance', 'tick_data', 'depth_analysis']
        },
        'risk_management': {
            'keywords': ['risk', 'drawdown', 'stop loss', 'position sizing'],
            'logic': 'RISK_METRIC AND CONTROL_RULE',
            'variations': ['vol_target', 'max_drawdown', 'correlation_limit']
        }
    }
    
    def __init__(self):
        self.extracted_patterns = []
    
    def process_materials(self, materials: List[Dict]) -> List[Dict]:
        """å¤„ç†æ‰€æœ‰ç´ æï¼Œæå–æ¨¡å¼"""
        print("\n" + "="*70)
        print("ğŸ” PATTERN RECOGNITION")
        print("="*70)
        
        patterns = []
        
        for material in materials:
            extracted = self._extract_from_material(material)
            patterns.extend(extracted)
        
        # å»é‡å’Œèšåˆ
        unique_patterns = self._aggregate_patterns(patterns)
        
        print(f"\nâœ… Extracted {len(unique_patterns)} unique patterns")
        return unique_patterns
    
    def _extract_from_material(self, material: Dict) -> List[Dict]:
        """ä»å•ä¸ªç´ ææå–æ¨¡å¼"""
        patterns = []
        text = f"{material.get('title', '')} {material.get('content', '')}".lower()
        
        for pattern_name, pattern_def in self.PATTERN_LIBRARY.items():
            score = 0
            matched_keywords = []
            
            for kw in pattern_def['keywords']:
                if kw.lower() in text:
                    score += 1
                    matched_keywords.append(kw)
            
            if score >= 2:  # è‡³å°‘åŒ¹é…2ä¸ªå…³é”®è¯
                patterns.append({
                    'pattern_type': pattern_name,
                    'logic_skeleton': pattern_def['logic'],
                    'confidence': min(score / len(pattern_def['keywords']) * 1.5, 1.0),
                    'matched_keywords': matched_keywords,
                    'source': material['source'],
                    'source_id': material['source_id'],
                    'variations': pattern_def['variations'],
                    'extracted_at': datetime.now().isoformat()
                })
        
        return patterns
    
    def _aggregate_patterns(self, patterns: List[Dict]) -> List[Dict]:
        """èšåˆåŒç±»æ¨¡å¼"""
        grouped = {}
        
        for p in patterns:
            key = p['pattern_type']
            if key not in grouped:
                grouped[key] = []
            grouped[key].append(p)
        
        aggregated = []
        for pattern_type, group in grouped.items():
            # åˆå¹¶åŒç±»æ¨¡å¼
            aggregated.append({
                'pattern_type': pattern_type,
                'occurrence_count': len(group),
                'avg_confidence': sum(p['confidence'] for p in group) / len(group),
                'sources': list(set(p['source'] for p in group)),
                'logic_skeleton': group[0]['logic_skeleton'],
                'variations': group[0]['variations'],
                'examples': [p['source_id'] for p in group[:3]]  # ä¿ç•™3ä¸ªç¤ºä¾‹
            })
        
        # æŒ‰å‡ºç°æ¬¡æ•°æ’åº
        return sorted(aggregated, key=lambda x: -x['occurrence_count'])


class InfiniteEvolutionLoop:
    """
    æ— é™è¿›åŒ–å¾ªç¯
    å…¨è‡ªåŠ¨ã€æ— äººå·¥å¹²é¢„ã€æŒç»­è¿è¡Œ
    """
    
    def __init__(self, db_path: str = "evolution_hub.db"):
        self.db_path = db_path
        self.miners = DataSourceMiners()
        self.recognizer = PatternRecognitionEngine()
        self.generation = 0
        self.running = False
        
        # çŠ¶æ€è¿½è¸ª
        self.state_history = []
        self.best_performers = []
        
    def start(self, mode: str = 'continuous'):
        """
        å¯åŠ¨è¿›åŒ–
        
        mode: 'continuous' - æŒç»­è¿è¡Œ
              'single' - å•è½®è¿è¡Œ
              'scheduled' - å®šæ—¶è¿è¡Œ
        """
        print("\n" + "="*70)
        print("ğŸ§¬ QUANT GENIUS NATION - INFINITE EVOLUTION STARTED")
        print("="*70)
        print(f"Mode: {mode}")
        print(f"Database: {self.db_path}")
        print(f"Start time: {datetime.now()}")
        print()
        
        if mode == 'continuous':
            self._continuous_loop()
        elif mode == 'single':
            self._evolution_cycle()
        elif mode == 'scheduled':
            self._scheduled_loop()
    
    def _continuous_loop(self):
        """æŒç»­è¿è¡Œå¾ªç¯"""
        self.running = True
        cycle_count = 0
        
        while self.running:
            cycle_count += 1
            print(f"\n{'='*70}")
            print(f"ğŸ”„ EVOLUTION CYCLE #{cycle_count}")
            print(f"{'='*70}")
            
            try:
                self._evolution_cycle()
                
                # çŠ¶æ€æŠ¥å‘Š
                if cycle_count % 5 == 0:
                    self._generate_report()
                
                # ä¼‘æ¯é—´éš”
                print(f"\nâ³ Resting for 60 seconds...")
                time.sleep(60)
                
            except Exception as e:
                print(f"\nâŒ Cycle failed: {e}")
                print("Restarting in 30 seconds...")
                time.sleep(30)
    
    def _scheduled_loop(self):
        """å®šæ—¶è¿è¡Œ"""
        # è®¾ç½®å®šæ—¶ä»»åŠ¡
        schedule.every(2).hours.do(self._evolution_cycle)
        schedule.every().day.at("08:00").do(self._generate_report)
        
        print("Scheduled tasks:")
        print("  - Evolution cycle: every 2 hours")
        print("  - Daily report: 08:00")
        
        while True:
            schedule.run_pending()
            time.sleep(60)
    
    def _evolution_cycle(self):
        """å•è½®è¿›åŒ–å‘¨æœŸ"""
        self.generation += 1
        cycle_start = datetime.now()
        
        # 1. ç´ ææŒ–æ˜
        print("\nğŸ“¥ PHASE 1: MATERIAL MINING")
        materials = self.miners.mine_all()
        
        # 2. æ¨¡å¼è¯†åˆ«
        print("\nğŸ§  PHASE 2: PATTERN RECOGNITION")
        patterns = self.recognizer.process_materials(materials)
        
        # 3. åŸºå› å·¥ç¨‹ï¼ˆå®ä¾‹åŒ–æ¨¡å¼ä¸ºåŸºå› ï¼‰
        print("\nğŸ”¬ PHASE 3: GENE ENGINEERING")
        new_genes = self._engineer_genes(patterns)
        
        # 4. æ³¨å…¥åŸºå› æ± 
        print("\nğŸ’‰ PHASE 4: GENE POOL INJECTION")
        injected = self._inject_genes(new_genes)
        
        # 5. ç”Ÿå­˜æŒ‘æˆ˜
        print("\nğŸ¦ PHASE 5: SURVIVAL CHALLENGE")
        survivors = self._run_survival_challenge()
        
        # 6. ç¹è¡è¿›åŒ–
        print("\nğŸ§¬ PHASE 6: EVOLUTION & BREEDING")
        offspring = self._breed_offspring(survivors)
        
        # 7. çŸ¥è¯†æ²‰æ·€
        print("\nğŸ“š PHASE 7: KNOWLEDGE PERSISTENCE")
        self._persist_knowledge()
        
        # è®°å½•çŠ¶æ€
        cycle_end = datetime.now()
        self._record_state({
            'generation': self.generation,
            'materials': len(materials),
            'patterns': len(patterns),
            'new_genes': len(new_genes),
            'injected': injected,
            'survivors': len(survivors),
            'offspring': len(offspring),
            'duration': (cycle_end - cycle_start).total_seconds()
        })
        
        print(f"\nâœ… Cycle {self.generation} complete in {(cycle_end - cycle_start).total_seconds():.1f}s")
    
    def _engineer_genes(self, patterns: List[Dict]) -> List[Dict]:
        """å°†æ¨¡å¼å·¥ç¨‹åŒ–ä¸ºåŸºå› """
        genes = []
        
        for pattern in patterns:
            # åŸºäºæ¨¡å¼ç±»å‹åˆ›å»ºä¸åŒå˜ä½“
            variations = self._create_variations(pattern)
            genes.extend(variations)
        
        # é™åˆ¶æ¯è½®æ–°åŸºå› æ•°é‡
        if len(genes) > 50:
            # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œä¿ç•™top 50
            genes = sorted(genes, key=lambda x: -x.get('confidence', 0))[:50]
        
        print(f"   Engineered {len(genes)} gene candidates")
        return genes
    
    def _create_variations(self, pattern: Dict) -> List[Dict]:
        """ä¸ºæ¨¡å¼åˆ›å»ºå‚æ•°å˜ä½“"""
        variations = []
        
        base_gene = {
            'name': f"PATTERN_{pattern['pattern_type'].upper()}_{self.generation}",
            'pattern_type': pattern['pattern_type'],
            'logic': pattern['logic_skeleton'],
            'source_pattern': pattern,
            'confidence': pattern['avg_confidence'],
            'generation': self.generation
        }
        
        # ä¸ºæ¯ä¸ªå˜ä½“åˆ›å»º
        for i, var in enumerate(pattern.get('variations', [])[:3]):
            gene = base_gene.copy()
            gene['name'] = f"{base_gene['name']}_V{i}"
            gene['variation'] = var
            gene['formula'] = self._generate_formula(pattern['pattern_type'], var)
            variations.append(gene)
        
        return variations
    
    def _generate_formula(self, pattern_type: str, variation: str) -> str:
        """ç”Ÿæˆå…·ä½“å…¬å¼"""
        templates = {
            'breakout_patterns': {
                'volume_confirm': 'close > max(high[-20:]) AND volume > mean(volume[-20:]) * 1.5',
                'time_confirm': 'close > max(high[-20:]) AND sustained(3)',
                'multi_tf_confirm': 'daily_breakout AND weekly_uptrend'
            },
            'reversal_patterns': {
                'rsi_extreme': 'RSI(close, 14) < 30 AND divergence(bullish)',
                'bollinger_extreme': 'close < lower_band AND volume_climax',
                'zscore_extreme': 'abs(zscore(close, 20)) > 2 AND reverting'
            },
            'trend_following': {
                'ma_cross': 'MA(close, 20) > MA(close, 60) AND close > MA(close, 20)',
                'macd_signal': 'MACD_line > signal_line AND histogram > 0',
                'adx_filter': 'ADX(14) > 25 AND DI+ > DI-'
            }
        }
        
        pt = templates.get(pattern_type, {})
        return pt.get(variation, f'{pattern_type}_{variation}')
    
    def _inject_genes(self, genes: List[Dict]) -> int:
        """æ³¨å…¥åŸºå› åˆ°æ•°æ®åº“"""
        import hashlib
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ç¡®ä¿è¡¨å­˜åœ¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS genes (
                gene_id TEXT PRIMARY KEY,
                name TEXT,
                description TEXT,
                formula TEXT,
                parameters TEXT,
                source TEXT,
                author TEXT,
                created_at TEXT,
                parent_gene_id TEXT,
                generation INTEGER DEFAULT 0
            )
        ''')
        
        inserted = 0
        for gene in genes:
            try:
                gene_id = hashlib.sha256(gene['formula'].encode()).hexdigest()[:16]
                
                cursor.execute('''
                    INSERT OR IGNORE INTO genes VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    gene_id,
                    gene['name'],
                    f"Pattern: {gene['pattern_type']}, Variation: {gene.get('variation', 'default')}",
                    gene['formula'],
                    json.dumps({'confidence': gene.get('confidence', 0), 'variation': gene.get('variation', '')}),
                    f"pattern_extraction:{gene['pattern_type']}",
                    "QuantGeniusNation",
                    datetime.now().isoformat(),
                    None,
                    gene.get('generation', self.generation)
                ))
                
                if cursor.rowcount > 0:
                    inserted += 1
                    
            except Exception as e:
                print(f"   âš ï¸  Injection error: {e}")
        
        conn.commit()
        conn.close()
        
        print(f"   Injected {inserted}/{len(genes)} new genes")
        return inserted
    
    def _run_survival_challenge(self) -> List[Dict]:
        """è¿è¡Œç”Ÿå­˜æŒ‘æˆ˜"""
        try:
            from darwin_selection_v2 import UnifiedDarwinSystem
            
            system = UnifiedDarwinSystem(self.db_path)
            result = system.survival_challenge_v2()
            
            print(f"   Survivors: {result['survivors']}/{result['total']}")
            return [{'gene_id': 'placeholder', 'fitness': 1.0}] * result['survivors']
            
        except Exception as e:
            print(f"   âš ï¸  Survival challenge error: {e}")
            return []
    
    def _breed_offspring(self, survivors: List[Dict]) -> List[Dict]:
        """ç¹è¡åä»£"""
        # ç®€åŒ–çš„ç¹è¡é€»è¾‘
        offspring = []
        
        # äº¤å‰
        if len(survivors) >= 2:
            for i in range(min(len(survivors), 10)):  # æœ€å¤š10ä¸ªåä»£
                offspring.append({
                    'type': 'crossover',
                    'parents': [survivors[i % len(survivors)], survivors[(i+1) % len(survivors)]]
                })
        
        # å˜å¼‚
        for s in survivors[:5]:  # å‰5ä¸ªå¹¸å­˜è€…å˜å¼‚
            offspring.append({
                'type': 'mutation',
                'parent': s
            })
        
        print(f"   Created {len(offspring)} offspring")
        return offspring
    
    def _persist_knowledge(self):
        """çŸ¥è¯†æŒä¹…åŒ–"""
        # ä¿å­˜çŠ¶æ€å†å²
        state_file = Path('/Users/oneday/.openclaw/workspace/memory/state/evolution_state.json')
        state_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(state_file, 'w') as f:
            json.dump({
                'last_update': datetime.now().isoformat(),
                'generation': self.generation,
                'history': self.state_history[-100:]  # ä¿ç•™æœ€è¿‘100æ¡
            }, f, indent=2)
        
        print("   Knowledge persisted")
    
    def _record_state(self, state: Dict):
        """è®°å½•çŠ¶æ€"""
        self.state_history.append(state)
        
        # æ§åˆ¶å°è¾“å‡º
        print(f"\nğŸ“Š STATE RECORD:")
        print(f"   Generation: {state['generation']}")
        print(f"   Materials: {state['materials']}")
        print(f"   Patterns: {state['patterns']}")
        print(f"   New genes: {state['new_genes']}")
        print(f"   Injected: {state['injected']}")
        print(f"   Survivors: {state['survivors']}")
        print(f"   Duration: {state['duration']:.1f}s")
    
    def _generate_report(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        print("\n" + "="*70)
        print("ğŸ“ˆ EVOLUTION REPORT")
        print("="*70)
        
        if not self.state_history:
            print("No data yet")
            return
        
        recent = self.state_history[-10:]
        
        print(f"\nLast 10 cycles summary:")
        print(f"  Avg materials/cycle: {sum(s['materials'] for s in recent)/len(recent):.1f}")
        print(f"  Avg patterns/cycle: {sum(s['patterns'] for s in recent)/len(recent):.1f}")
        print(f"  Avg new genes/cycle: {sum(s['new_genes'] for s in recent)/len(recent):.1f}")
        print(f"  Total survivors: {recent[-1]['survivors'] if recent else 0}")
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        report_path = Path('/Users/oneday/.openclaw/workspace/memory/reports')
        report_path.mkdir(parents=True, exist_ok=True)
        
        report_file = report_path / f"evolution_report_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
        with open(report_file, 'w') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'generation': self.generation,
                'summary': self.state_history
            }, f, indent=2)
        
        print(f"\nReport saved: {report_file}")


def main():
    """ä¸»å…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Quant Genius Nation')
    parser.add_argument('--mode', '-m', default='single', 
                       choices=['single', 'continuous', 'scheduled'],
                       help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--db', default='evolution_hub.db', help='æ•°æ®åº“è·¯å¾„')
    
    args = parser.parse_args()
    
    # å¯åŠ¨è¿›åŒ–
    nation = InfiniteEvolutionLoop(args.db)
    nation.start(mode=args.mode)


if __name__ == '__main__':
    main()
